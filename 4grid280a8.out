--------------------------------------------------------------------------
[[9278,1],6]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: euca-128-84-11-54

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
Using MPI version 3.0, 12 processes
command-line param: no-struct=false
command-line param: no-holes=false
command-line param: nfreq=8
-----------
Initializing structure...
Working in 3D dimensions.
Computational cell is 4 x 4 x 5 with resolution 40
     block, center = (0,0,0)
          size (1e+20,1e+20,0.15)
          axes (1,0,0), (0,1,0), (0,0,1)
          dielectric constant epsilon diagonal = (12,12,12)
     block, center = (2,3,0)
          size (4,0.28,0.15)
          axes (1,0,0), (0,1,0), (0,0,1)
          dielectric constant epsilon diagonal = (1,1,1)
     block, center = (2,1,0)
          size (4,0.28,0.15)
          axes (1,0,0), (0,1,0), (0,0,1)
          dielectric constant epsilon diagonal = (1,1,1)
     block, center = (1,2,0)
          size (0.28,4,0.15)
          axes (1,0,0), (0,1,0), (0,0,1)
          dielectric constant epsilon diagonal = (1,1,1)
     block, center = (3,2,0)
          size (0.28,4,0.15)
          axes (1,0,0), (0,1,0), (0,0,1)
          dielectric constant epsilon diagonal = (1,1,1)
subpixel-averaging is 91.9933% done, 0.351893 s remaining
subpixel-averaging is 73.9213% done, 1.42166 s remaining
subpixel-averaging is 72.0161% done, 1.56088 s remaining
subpixel-averaging is 99.6141% done, 0.0156565 s remaining
subpixel-averaging is 73.1592% done, 1.4733 s remaining
time for set_epsilon = 30.1463 s
time for set_conductivity = 0.276601 s
time for set_conductivity = 0.292054 s
time for set_conductivity = 0.292576 s
-----------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 5 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
